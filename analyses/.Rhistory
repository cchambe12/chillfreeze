sample(x, size = ntot, replace = TRUE)})
# Determine which environmental variables interact
intrxnname <- names(model.parameters)[5] # interaction terms
names.temp <- gsub("x", "|", intrxnname) # remove text to align with colnames
env.pairs <- sapply(1:length(names.temp), FUN = function(X){
grep(pattern = names.temp[X], x = colnames(env.samples))
})
# Add these interactions (product) to env.samples
env.interactions <- sapply(1:ncol(env.pairs), FUN = function(X){
apply(env.samples[, env.pairs[, X]], MARGIN = 1, FUN = prod)
})
env.samples2 <- cbind(env.samples, env.interactions)
# Create model matrix
mm <- model.matrix(~env.samples2)
# Calculate response
response <- sapply(1:nrow(env.samples), FUN = function(x){
rnorm(n = 1, mean = mm[x, ], sd = 10)})
rti_testdata_intrxn <- cbind(data.frame(intention = response, provider = env.samples[,1], uncertainty = env.samples[,2],
language = env.samples[,3]))
write.csv(rti_testdata_intrxn, file="~/Desktop/rti_testdata_intrxn.csv", row.names = FALSE)
#  7) Let's do a quick lmer model to test the fake data
modtest <- lm(intention ~ provider + uncertainty + language + uncertainty*language, data=rti_testdata_intrxn) ## Quick look looks good!
modtest
display(modtest)
library(arm)
display(modtest)
#  1) Let's make the observations much higher than the actual data to build a good model.
ntot = 1000 # numbers of obs per species.
sample_a <- list(prov.env = rbinom(ntot, 1, 0.5),
unc.env = rbinom(ntot, 1, 0.5),
lang.env = rbinom(ntot, 1, 0.5))
model.parameters <- list(intercept = 0,
prov.coef = -5,
unc.coef = 10,
lang.coef = 10,
uncxlang = 5
)
#  2) Now, we will make varying intercepts
env.samples <- sapply(sample_a, FUN = function(x){
sample(x, size = ntot, replace = TRUE)})
# Determine which environmental variables interact
intrxnname <- names(model.parameters)[5] # interaction terms
names.temp <- gsub("x", "|", intrxnname) # remove text to align with colnames
env.pairs <- sapply(1:length(names.temp), FUN = function(X){
grep(pattern = names.temp[X], x = colnames(env.samples))
})
# Add these interactions (product) to env.samples
env.interactions <- sapply(1:ncol(env.pairs), FUN = function(X){
apply(env.samples[, env.pairs[, X]], MARGIN = 1, FUN = prod)
})
env.samples2 <- cbind(env.samples, env.interactions)
# Create model matrix
mm <- model.matrix(~env.samples2)
# Calculate response
response <- sapply(1:nrow(env.samples), FUN = function(x){
rnorm(n = 1, mean = mm[x, ], sd = 10)})
rti_testdata_intrxn <- cbind(data.frame(intention = response, provider = env.samples[,1], uncertainty = env.samples[,2],
language = env.samples[,3]))
write.csv(rti_testdata_intrxn, file="~/Desktop/rti_testdata_intrxn.csv", row.names = FALSE)
#  7) Let's do a quick lmer model to test the fake data
modtest <- lm(intention ~ provider + uncertainty + language + uncertainty*language, data=rti_testdata_intrxn) ## Quick look looks good!
display(modtest)
#  Let's make the observations much higher than the actual data to build a good model.
ntot = 175 # numbers of obs per species.
sample_a <- list(prov.env = rbinom(ntot, 1, 0.5),
unc.env = rbinom(ntot, 1, 0.5),
lang.env = rbinom(ntot, 1, 0.5))
model.parameters <- list(intercept = 0,
prov.coef = -5,
unc.coef = 10,
lang.coef = 10,
uncxlang = 5
)
#  Now, we will make varying intercepts
env.samples <- sapply(sample_a, FUN = function(x){
sample(x, size = ntot, replace = TRUE)})
# Determine which environmental variables interact
intrxnname <- names(model.parameters)[5] # interaction terms
names.temp <- gsub("x", "|", intrxnname) # remove text to align with colnames
env.pairs <- sapply(1:length(names.temp), FUN = function(X){
grep(pattern = names.temp[X], x = colnames(env.samples))
})
# Add these interactions (product) to env.samples
env.interactions <- sapply(1:ncol(env.pairs), FUN = function(X){
apply(env.samples[, env.pairs[, X]], MARGIN = 1, FUN = prod)
})
env.samples2 <- cbind(env.samples, env.interactions)
# Create model matrix
mm <- model.matrix(~env.samples2)
parameters.temp <- matrix(unlist(model.parameters), ncol = length(model.parameters), nrow = ntot, byrow = TRUE)
# Generate parameters
parameters.temp[, 1] <- sapply(1:nsp, FUN = function(x){
rep(rnorm(n = 1, mean = model.parameters, sd = 0.5), ntot)})
parameters.temp[, 2] <- sapply(1:nsp, FUN = function(x){
rep(rnorm(n = 1, mean = model.parameters, sd = 0.5), ntot)})
parameters.temp[, 3] <- sapply(1:nsp, FUN = function(x){
rep(rnorm(n = 1, mean = model.parameters, sd = 0.5), ntot)})
parameters.temp[, 3] <- sapply(1:nsp, FUN = function(x){
rep(rnorm(n = 1, mean = model.parameters, sd = 0.5), ntot)})
# Calculate response
response <- sapply(1:nrow(env.samples), FUN = function(x){
rnorm(n = 1, mean = mm[x, ] %*% parameters.temp[x, ], sd = 1)})
# Generate parameters
parameters.temp[, 1] <- sapply(1, FUN = function(x){
rep(rnorm(n = 1, mean = model.parameters, sd = 0.5), ntot)})
parameters.temp[, 2] <- sapply(1, FUN = function(x){
rep(rnorm(n = 1, mean = model.parameters, sd = 0.5), ntot)})
parameters.temp[, 3] <- sapply(1, FUN = function(x){
rep(rnorm(n = 1, mean = model.parameters, sd = 0.5), ntot)})
parameters.temp[, 3] <- sapply(1, FUN = function(x){
rep(rnorm(n = 1, mean = model.parameters, sd = 0.5), ntot)})
# Calculate response
response <- sapply(1:nrow(env.samples), FUN = function(x){
rnorm(n = 1, mean = mm[x, ] %*% parameters.temp[x, ], sd = 1)})
# Generate parameters
parameters.temp[, 1] <- rep(rnorm(n = 1, mean = model.parameters, sd = 0.5), ntot)
mean = model.parameters
model.parameters
# Generate parameters
parameters.temp[, 1] <- rep(rnorm(n = 1, mean = model.parameters[[1]], sd = 0.5), ntot)
parameters.temp[, 2] <- rep(rnorm(n = 1, mean = model.parameters[[2]], sd = 0.5), ntot)
parameters.temp[, 3] <- rep(rnorm(n = 1, mean = model.parameters[[3]], sd = 0.5), ntot)
parameters.temp[, 3] <- rep(rnorm(n = 1, mean = model.parameters[[4]], sd = 0.5), ntot)
# Calculate response
response <- sapply(1:nrow(env.samples), FUN = function(x){
rnorm(n = 1, mean = mm[x, ] %*% parameters.temp[x, ], sd = 1)})
rti_testdata_intrxn <- cbind(data.frame(intention = response, provider = env.samples[,1], uncertainty = env.samples[,2],
language = env.samples[,3]))
write.csv(rti_testdata_intrxn, file="~/Desktop/rti_testdata_intrxn.csv", row.names = FALSE)
#  Let's do a quick lmer model to test the fake data
modtest <- lm(intention ~ provider + uncertainty + language + uncertainty*language, data=rti_testdata_intrxn) ## Quick look looks good!
summary(modtest)
#  Let's make the observations much higher than the actual data to build a good model.
ntot = 175 # numbers of obs per species.
sample_a <- list(prov.env = rbinom(ntot, 1, 0.5),
unc.env = rbinom(ntot, 1, 0.5),
lang.env = rbinom(ntot, 1, 0.5))
model.parameters <- list(intercept = 0,
prov.coef = -5,
unc.coef = 10,
lang.coef = 10,
uncxlang = 5
)
#  Now, we will make varying intercepts
env.samples <- sapply(sample_a, FUN = function(x){
sample(x, size = ntot, replace = TRUE)})
# Determine which environmental variables interact
intrxnname <- names(model.parameters)[5] # interaction terms
names.temp <- gsub("x", "|", intrxnname) # remove text to align with colnames
env.pairs <- sapply(1:length(names.temp), FUN = function(X){
grep(pattern = names.temp[X], x = colnames(env.samples))
})
# Add these interactions (product) to env.samples
env.interactions <- sapply(1:ncol(env.pairs), FUN = function(X){
apply(env.samples[, env.pairs[, X]], MARGIN = 1, FUN = prod)
})
env.samples2 <- cbind(env.samples, env.interactions)
# Create model matrix
mm <- model.matrix(~env.samples2)
parameters.temp <- matrix(unlist(model.parameters), ncol = length(model.parameters), nrow = ntot, byrow = TRUE)
# Generate parameters
parameters.temp[, 1] <- rep(rnorm(n = 1, mean = model.parameters[[1]], sd = 2), ntot)
parameters.temp[, 2] <- rep(rnorm(n = 1, mean = model.parameters[[2]], sd = 2), ntot)
parameters.temp[, 3] <- rep(rnorm(n = 1, mean = model.parameters[[3]], sd = 2), ntot)
parameters.temp[, 3] <- rep(rnorm(n = 1, mean = model.parameters[[4]], sd = 2), ntot)
# Calculate response
response <- sapply(1:nrow(env.samples), FUN = function(x){
rnorm(n = 1, mean = mm[x, ] %*% parameters.temp[x, ], sd = 5)})
rti_testdata_intrxn <- cbind(data.frame(intention = response, provider = env.samples[,1], uncertainty = env.samples[,2],
language = env.samples[,3]))
write.csv(rti_testdata_intrxn, file="~/Desktop/rti_testdata_intrxn.csv", row.names = FALSE)
#  Let's do a quick lmer model to test the fake data
modtest <- lm(intention ~ provider + uncertainty + language + uncertainty*language, data=rti_testdata_intrxn) ## Quick look looks good!
summary(modtest)
#  Let's make the observations much higher than the actual data to build a good model.
ntot = 175 # numbers of obs per species.
sample_a <- list(prov.env = rbinom(ntot, 1, 0.5),
unc.env = rbinom(ntot, 1, 0.5),
lang.env = rbinom(ntot, 1, 0.5))
model.parameters <- list(intercept = 0,
prov.coef = -5,
unc.coef = 10,
lang.coef = 10,
uncxlang = 5
)
#  Now, we will make varying intercepts
env.samples <- sapply(sample_a, FUN = function(x){
sample(x, size = ntot, replace = TRUE)})
# Determine which environmental variables interact
intrxnname <- names(model.parameters)[5] # interaction terms
names.temp <- gsub("x", "|", intrxnname) # remove text to align with colnames
env.pairs <- sapply(1:length(names.temp), FUN = function(X){
grep(pattern = names.temp[X], x = colnames(env.samples))
})
# Add these interactions (product) to env.samples
env.interactions <- sapply(1:ncol(env.pairs), FUN = function(X){
apply(env.samples[, env.pairs[, X]], MARGIN = 1, FUN = prod)
})
env.samples2 <- cbind(env.samples, env.interactions)
# Create model matrix
mm <- model.matrix(~env.samples2)
parameters.temp <- matrix(unlist(model.parameters), ncol = length(model.parameters), nrow = ntot, byrow = TRUE)
# Generate parameters
parameters.temp[, 1] <- rep(rnorm(n = 1, mean = model.parameters[[1]], sd = 1), ntot)
parameters.temp[, 2] <- rep(rnorm(n = 1, mean = model.parameters[[2]], sd = 1), ntot)
parameters.temp[, 3] <- rep(rnorm(n = 1, mean = model.parameters[[3]], sd = 1), ntot)
parameters.temp[, 3] <- rep(rnorm(n = 1, mean = model.parameters[[4]], sd = 1), ntot)
# Calculate response
response <- sapply(1:nrow(env.samples), FUN = function(x){
rnorm(n = 1, mean = mm[x, ] %*% parameters.temp[x, ], sd = 2)})
rti_testdata_intrxn <- cbind(data.frame(intention = response, provider = env.samples[,1], uncertainty = env.samples[,2],
language = env.samples[,3]))
write.csv(rti_testdata_intrxn, file="~/Desktop/rti_testdata_intrxn.csv", row.names = FALSE)
#  Let's do a quick lmer model to test the fake data
modtest <- lm(intention ~ provider + uncertainty + language + uncertainty*language, data=rti_testdata_intrxn) ## Quick look looks good!
summary(modtest)
df(modtest)
#  Let's do a quick lmer model to test the fake data
modtest <- glm(intention ~ provider + uncertainty + language + uncertainty*language, data=rti_testdata_intrxn, family=binomial(link="logit")) ## Quick look looks good!
#  Let's make the observations much higher than the actual data to build a good model.
ntot = 175 # numbers of obs per species.
sample_a <- list(prov.env = rbinom(ntot, 1, 0.5),
unc.env = rbinom(ntot, 1, 0.5),
lang.env = rbinom(ntot, 1, 0.5))
model.parameters <- list(intercept = 0,
prov.coef = -0.05,
unc.coef = .1,
lang.coef = .10,
uncxlang = .05
)
#  Now, we will make varying intercepts
env.samples <- sapply(sample_a, FUN = function(x){
sample(x, size = ntot, replace = TRUE)})
# Determine which environmental variables interact
intrxnname <- names(model.parameters)[5] # interaction terms
names.temp <- gsub("x", "|", intrxnname) # remove text to align with colnames
env.pairs <- sapply(1:length(names.temp), FUN = function(X){
grep(pattern = names.temp[X], x = colnames(env.samples))
})
# Add these interactions (product) to env.samples
env.interactions <- sapply(1:ncol(env.pairs), FUN = function(X){
apply(env.samples[, env.pairs[, X]], MARGIN = 1, FUN = prod)
})
env.samples2 <- cbind(env.samples, env.interactions)
# Create model matrix
mm <- model.matrix(~env.samples2)
parameters.temp <- matrix(unlist(model.parameters), ncol = length(model.parameters), nrow = ntot, byrow = TRUE)
# Generate parameters
parameters.temp[, 1] <- rep(rnorm(n = 1, mean = model.parameters[[1]], sd = 1), ntot)
parameters.temp[, 2] <- rep(rnorm(n = 1, mean = model.parameters[[2]], sd = 1), ntot)
parameters.temp[, 3] <- rep(rnorm(n = 1, mean = model.parameters[[3]], sd = 1), ntot)
parameters.temp[, 3] <- rep(rnorm(n = 1, mean = model.parameters[[4]], sd = 1), ntot)
# Calculate response
response <- sapply(1:nrow(env.samples), FUN = function(x){
rnorm(n = 1, mean = mm[x, ] %*% parameters.temp[x, ], sd = 2)})
rti_testdata_intrxn <- cbind(data.frame(intention = response, provider = env.samples[,1], uncertainty = env.samples[,2],
language = env.samples[,3]))
write.csv(rti_testdata_intrxn, file="~/Desktop/rti_testdata_intrxn.csv", row.names = FALSE)
#  Let's do a quick lmer model to test the fake data
modtest <- glm(intention ~ provider + uncertainty + language + uncertainty*language, data=rti_testdata_intrxn, family=binomial(link="logit")) ## Quick look looks good!
response
# Calculate response
response <- sapply(1:nrow(env.samples), FUN = function(x){
rbeta(n = 1, mean = mm[x, ] %*% parameters.temp[x, ], sd = 2)})
# Calculate response
response <- sapply(1:nrow(env.samples), FUN = function(x){
dbeta(n = 1, mean = mm[x, ] %*% parameters.temp[x, ], sd = 2)})
modtest.anova <- anova(intention ~ provider + uncertainty + language + uncertainty*language, data=rti_testdata_intrxn)
modtest.anova <- anova(lm(intention ~ provider + uncertainty + language + uncertainty*language, data=rti_testdata_intrxn))
summary(modtest.anova)
modtest.anova
#  Let's make the observations much higher than the actual data to build a good model.
ntot = 175 # numbers of obs per species.
sample_a <- list(prov.env = rbinom(ntot, 1, 0.5),
unc.env = rbinom(ntot, 1, 0.5),
lang.env = rbinom(ntot, 1, 0.5))
model.parameters <- list(intercept = 0,
prov.coef = -5,
unc.coef = 10,
lang.coef = 10,
uncxlang = 5
)
#  Now, we will make varying intercepts
env.samples <- sapply(sample_a, FUN = function(x){
sample(x, size = ntot, replace = TRUE)})
# Determine which environmental variables interact
intrxnname <- names(model.parameters)[5] # interaction terms
names.temp <- gsub("x", "|", intrxnname) # remove text to align with colnames
env.pairs <- sapply(1:length(names.temp), FUN = function(X){
grep(pattern = names.temp[X], x = colnames(env.samples))
})
# Add these interactions (product) to env.samples
env.interactions <- sapply(1:ncol(env.pairs), FUN = function(X){
apply(env.samples[, env.pairs[, X]], MARGIN = 1, FUN = prod)
})
env.samples2 <- cbind(env.samples, env.interactions)
# Create model matrix
mm <- model.matrix(~env.samples2)
parameters.temp <- matrix(unlist(model.parameters), ncol = length(model.parameters), nrow = ntot, byrow = TRUE)
# Generate parameters
parameters.temp[, 1] <- rep(rnorm(n = 1, mean = model.parameters[[1]], sd = 1), ntot)
parameters.temp[, 2] <- rep(rnorm(n = 1, mean = model.parameters[[2]], sd = 1), ntot)
parameters.temp[, 3] <- rep(rnorm(n = 1, mean = model.parameters[[3]], sd = 1), ntot)
parameters.temp[, 3] <- rep(rnorm(n = 1, mean = model.parameters[[4]], sd = 1), ntot)
# Calculate response
response <- sapply(1:nrow(env.samples), FUN = function(x){
rnorm(n = 1, mean = mm[x, ] %*% parameters.temp[x, ], sd = 2)})
rti_testdata_intrxn <- cbind(data.frame(intention = response, provider = env.samples[,1], uncertainty = env.samples[,2],
language = env.samples[,3]))
write.csv(rti_testdata_intrxn, file="~/Desktop/rti_testdata_intrxn.csv", row.names = FALSE)
modtest.anova <- anova(lm(intention ~ provider + uncertainty + language + uncertainty*language, data=rti_testdata_intrxn))
summary(modtest.anova)
modtest.anova
# housekeeping
rm(list=ls())
options(stringsAsFactors = FALSE)
# Load libraries
library(RColorBrewer)
library(viridis)
library(broom.mixed)
library(rstan)
library(dplyr)
library(tidyr)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
# Set working directory
setwd("~/Documents/git/chillfreeze/analyses")
## load the model
load("stan/dvr_brms.Rdata")
#### Now for mu plots based of bb_analysis/models_stan_plotting.R ###
figpath <- "figures"
#### Now for mu plots based of bb_analysis/models_stan_plotting.R ###
figpath <- "figures"
figpathmore <- "dvr50and90_brms" ### change based on model
modelhere <- dvr.mod
xlab <- "Model estimate of change in \nduration of vegetative risk (days)"
if(FALSE){
##load("stan/rgr_prebudset_brms.Rdata")
##load("stan/htdiff_brms.Rdata")
##load("stan/roots_brms.Rdata")
##load("stan/shoots_brms.Rdata")
#load("stan/htfinalrate_brms.Rdata")
#load("stan/biomassrate_brms.Rdata")
#xlab <- "Model estimate of change in belowground biomass (g)"
#xlab <- "Model estimate of change in aboveground biomass (g)"
#xlab <- "Model estimate of change in shoot growth per day (mm/day)"
}
chill.stan <- read.csv("output/clean_dvr_traits.csv")
chill.stan$species.name <- NA
chill.stan$species.name <- ifelse(chill.stan$species=="ACESAC", "Acer saccharinum", chill.stan$species.name)
chill.stan$species.name <- ifelse(chill.stan$species=="ALNRUG", "Alnus rugosa", chill.stan$species.name)
chill.stan$species.name <- ifelse(chill.stan$species=="BETPAP", "Betula papyrifera", chill.stan$species.name)
chill.stan$species.name <- ifelse(chill.stan$species=="BETPOP", "Betula populifolia", chill.stan$species.name)
chill.stan$species.name <- ifelse(chill.stan$species=="CORRAC", "Cornus racemosa", chill.stan$species.name)
chill.stan$species.name <- ifelse(chill.stan$species=="SALPUR", "Salix purpurea", chill.stan$species.name)
chill.stan$species.name <- ifelse(chill.stan$species=="SORAME", "Sorbus americana", chill.stan$species.name)
chill.stan$species.name <- ifelse(chill.stan$species=="VIBDEN", "Viburnum dentatum", chill.stan$species.name)
chill.stan$species.name <- ifelse(chill.stan$species=="FAGGRA", "Fagus grandifolia", chill.stan$species.name)
chill.stan$species.name <- ifelse(chill.stan$species=="NYSSYL", "Nyssa sylvatica", chill.stan$species.name)
rmspp <- c("FAGGRA", "NYSSYL")
chill.stan <- chill.stan[!(chill.stan$species%in%rmspp),]
chill.stan$chillnew <- ifelse(chill.stan$chill==1, 3, NA)
chill.stan$chillnew <- ifelse(chill.stan$chill==2, 2, chill.stan$chillnew)
chill.stan$chillnew <- ifelse(chill.stan$chill==3, 1, chill.stan$chillnew)
chill.stan$chill1 = ifelse(chill.stan$chillnew == 2, 1, 0)
chill.stan$chill2 = ifelse(chill.stan$chillnew == 3, 1, 0)
cols <- adjustcolor("indianred3", alpha.f = 0.3)
my.pal <-viridis_pal(option="viridis")(8)
# display.brewer.all()
alphahere = 0.4
spp <- unique(chill.stan$species)
tx <- coef(modelhere, prob=c(0.10, 0.90))$species[, c(1, 3:4), 2] %>%
as.data.frame() %>%
round(digits = 2) %>%
dplyr::rename(mean = Estimate) %>%
dplyr::rename(`10%` = Q10) %>%
dplyr::rename(`90%` = Q90) %>%
dplyr::select(mean, `10%`, `90%`)
new.names<-NULL
for(i in 1:length(spp)){
new.names[i]<-paste("tx", "[", i, "]", sep="")
}
tx$parameter<-new.names
chill1 <- coef(modelhere, prob=c(0.10, 0.90))$species[, c(1, 3:4), 3] %>%
as.data.frame() %>%
round(digits = 2) %>%
dplyr::rename(mean = Estimate) %>%
dplyr::rename(`10%` = Q10) %>%
dplyr::rename(`90%` = Q90) %>%
dplyr::select( mean, `10%`, `90%`)
new.names<-NULL
for(i in 1:length(spp)){
new.names[i]<-paste("chill1", "[", i, "]", sep="")
}
chill1$parameter<-new.names
mod.ranef<-dplyr::full_join(tx, chill1)
chill2 <- coef(modelhere, prob=c(0.10, 0.90))$species[, c(1, 3:4), 4] %>%
as.data.frame() %>%
round(digits = 2) %>%
dplyr::rename(mean = Estimate) %>%
dplyr::rename(`10%` = Q10) %>%
dplyr::rename(`90%` = Q90) %>%
dplyr::select( mean, `10%`, `90%`)
new.names<-NULL
for(i in 1:length(spp)){
new.names[i]<-paste("chill2", "[", i, "]", sep="")
}
chill2$parameter<-new.names
mod.ranef <- dplyr::full_join(mod.ranef, chill2)
txchill1 <- coef(modelhere, prob=c(0.10, 0.90))$species[, c(1, 3:4), 5] %>%
as.data.frame() %>%
round(digits = 2) %>%
dplyr::rename(mean = Estimate) %>%
dplyr::rename(`10%` = Q10) %>%
dplyr::rename(`90%` = Q90) %>%
dplyr::select( mean, `10%`, `90%`)
new.names<-NULL
for(i in 1:length(spp)){
new.names[i]<-paste("tx:chill1", "[", i, "]", sep="")
}
txchill1$parameter<-new.names
mod.ranef<-dplyr::full_join(mod.ranef, txchill1)
txchill2 <- coef(modelhere, prob=c(0.10, 0.90))$species[, c(1, 3:4), 6] %>%
as.data.frame() %>%
round(digits = 2) %>%
dplyr::rename(mean = Estimate) %>%
dplyr::rename(`10%` = Q10) %>%
dplyr::rename(`90%` = Q90) %>%
dplyr::select( mean, `10%`, `90%`)
new.names<-NULL
for(i in 1:length(spp)){
new.names[i]<-paste("tx:chill2", "[", i, "]", sep="")
}
txchill2$parameter<-new.names
mod.ranef<-dplyr::full_join(mod.ranef, txchill2)
### Now to add on 50% cred intervals on top
tx50 <- coef(modelhere, prob=c(0.25, 0.75))$species[, c(1, 3:4), 2] %>%
as.data.frame() %>%
round(digits = 2) %>%
dplyr::rename(mean = Estimate) %>%
dplyr::rename(`25%` = Q25) %>%
dplyr::rename(`75%` = Q75) %>%
dplyr::select(mean, `25%`, `75%`)
new.names<-NULL
for(i in 1:length(spp)){
new.names[i]<-paste("tx", "[", i, "]", sep="")
}
tx50$parameter<-new.names
chill150 <- coef(modelhere, prob=c(0.25, 0.75))$species[, c(1, 3:4), 3] %>%
as.data.frame() %>%
round(digits = 2) %>%
dplyr::rename(mean = Estimate) %>%
dplyr::rename(`25%` = Q25) %>%
dplyr::rename(`75%` = Q75) %>%
dplyr::select(mean, `25%`, `75%`)
new.names<-NULL
for(i in 1:length(spp)){
new.names[i]<-paste("chill1", "[", i, "]", sep="")
}
chill150$parameter<-new.names
mod.ranef50<-dplyr::full_join(tx50, chill150)
chill250 <- coef(modelhere, prob=c(0.25, 0.75))$species[, c(1, 3:4), 4] %>%
as.data.frame() %>%
round(digits = 2) %>%
dplyr::rename(mean = Estimate) %>%
dplyr::rename(`25%` = Q25) %>%
dplyr::rename(`75%` = Q75) %>%
dplyr::select(mean, `25%`, `75%`)
new.names<-NULL
for(i in 1:length(spp)){
new.names[i]<-paste("chill2", "[", i, "]", sep="")
}
chill250$parameter<-new.names
mod.ranef50 <- dplyr::full_join(mod.ranef50, chill250)
txchill150 <- coef(modelhere, prob=c(0.25, 0.75))$species[, c(1, 3:4), 5] %>%
as.data.frame() %>%
round(digits = 2) %>%
dplyr::rename(mean = Estimate) %>%
dplyr::rename(`25%` = Q25) %>%
dplyr::rename(`75%` = Q75) %>%
dplyr::select(mean, `25%`, `75%`)
new.names<-NULL
for(i in 1:length(spp)){
new.names[i]<-paste("tx:chill1", "[", i, "]", sep="")
}
txchill150$parameter<-new.names
mod.ranef50<-dplyr::full_join(mod.ranef50, txchill150)
txchill250 <- coef(modelhere, prob=c(0.25, 0.75))$species[, c(1, 3:4), 6] %>%
as.data.frame() %>%
round(digits = 2) %>%
dplyr::rename(mean = Estimate) %>%
dplyr::rename(`25%` = Q25) %>%
dplyr::rename(`75%` = Q75) %>%
dplyr::select(mean, `25%`, `75%`)
new.names<-NULL
for(i in 1:length(spp)){
new.names[i]<-paste("tx:chill2", "[", i, "]", sep="")
}
txchill250$parameter<-new.names
mod.ranef50<-dplyr::full_join(mod.ranef50, txchill250)
mod.ranef <- dplyr::left_join(mod.ranef, mod.ranef50)
modoutput <- tidy(modelhere, conf.level=c(0.9))
mod50 <- tidy(modelhere, conf.level =c(0.5))
names(mod50) <- c("","","", "term", "estimate", "std.error", "low50", "high50")
mod50 <- mod50[4:8]
names(modoutput) <- c("","","", "term", "estimate", "std.error", "lower", "upper")
modoutput <- modoutput[4:8]
modoutput <- dplyr::left_join(modoutput, mod50)
modoutput <-modoutput[-1,]
#quartz()
source("source/exp_muplot_brms.R")
muplotfx(modelhere, "", 8, 8, c(0,5), c(-10, 10) , 11, 3.5) ## use for DVR
